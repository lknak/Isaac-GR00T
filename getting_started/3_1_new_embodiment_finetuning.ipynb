{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 New Embodiment Finetuning Tutorial (Python API)\n",
    "\n",
    "This provides a step-by-step guide on how to finetune GR00T-N1.5 with our python API, the G1 Block Stacking Dataset is used as an example.\n",
    "\n",
    "This is a more detailed version of the [3_0_new_embodiment_finetuning.md](3_0_new_embodiment_finetuning.md) tutorial, which explains in-depth the details of configuring the dataset, transforms, and finetuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Dataset\n",
    "\n",
    "Loading any dataset for finetuning can be done in 2 steps:\n",
    "- 1.1: Defining the modality configs and transforms for the dataset\n",
    "- 1.2: Loading the dataset using the `LeRobotSingleDataset` class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step: 1.0 Download the dataset\n",
    "\n",
    "- Download the dataset from: https://huggingface.co/datasets/unitreerobotics/G1_BlockStacking_Dataset\n",
    "- copy over the `examples/unitree_g1_blocks__modality.json` to the dataset `<DATASET_PATH>/meta/modality.json`\n",
    "  - This provides additional information about the state and action modalities to make it \"GR00T-compatible\"\n",
    "  - `cp examples/unitree_g1_blocks__modality.json datasets/G1_BlockStacking_Dataset/meta/modality.json`\n",
    "\n",
    "\n",
    "**Understanding the Modality Configs**\n",
    "\n",
    "This file provides detailed metadata about state and action modalities, enabling:\n",
    "\n",
    "- **Separate Data Storage and Interpretation:**\n",
    "  - **State and Action:** Stored as concatenated float32 arrays. The `modality.json` file supplies the metadata necessary to interpret these arrays as distinct, fine-grained fields with additional training information.\n",
    "  - **Video:** Stored as separate files, with the configuration file allowing them to be renamed to a standardized format.\n",
    "  - **Annotations:** Keeps track of all annotation fields. If there are no annotations, do not include the `annotation` field in the configuration file.\n",
    "- **Fine-Grained Splitting:** Divides the state and action arrays into more semantically meaningful fields.\n",
    "- **Clear Mapping:** Explicit mapping of data dimensions.\n",
    "- **Sophisticated Data Transformations:** Supports field-specific normalization and rotation transformations during training.\n",
    "\n",
    "#### Schema\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"state\": {\n",
    "        \"<state_name>\": {\n",
    "            \"start\": <int>,         // Starting index in the state array\n",
    "            \"end\": <int>,           // Ending index in the state array\n",
    "        }\n",
    "    },\n",
    "    \"action\": {\n",
    "        \"<action_name>\": {\n",
    "            \"start\": <int>,         // Starting index in the action array\n",
    "            \"end\": <int>,           // Ending index in the action array\n",
    "        }\n",
    "    },\n",
    "    \"video\": {\n",
    "        \"<video_name>\": {}  // Empty dictionary to maintain consistency with other modalities\n",
    "    },\n",
    "    \"annotation\": {\n",
    "        \"<annotation_name>\": {}  // Empty dictionary to maintain consistency with other modalities\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Example is shown in `getting_started/examples/unitree_g1_blocks__modality.json`. This file is located in the `meta` folder of the lerobot dataset.\n",
    "\n",
    "\n",
    "Generate the Stats (`meta/metadata.json`) by running the following command:\n",
    "```bash\n",
    "python scripts/load_dataset.py --data_path /datasets/G1_BlockStacking_Dataset/ --embodiment_tag new_embodiment\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gr00t.data.schema import EmbodimentTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"~/.cache/huggingface/hub/datasets--unitreerobotics--G1_Dex3_BlockStacking_Dataset/snapshots/57faa2cf516e008f96d91fe3b67ad53a74f012e6\"  # change this to your dataset path\n",
    "embodiment_tag = EmbodimentTag.NEW_EMBODIMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step: 1.1 Modality configs and transforms\n",
    "\n",
    "Modality configs let you select which specific data streams to use for each input type (video, state, action, language, etc.) during finetuning, giving you precise control over which parts of your dataset are utilized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gr00t.data.dataset import ModalityConfig\n",
    "\n",
    "\n",
    "# select the modality keys you want to use for finetuning\n",
    "video_modality = ModalityConfig(\n",
    "    delta_indices=[0],\n",
    "    modality_keys=[\"video.cam_right_high\"],\n",
    ")\n",
    "\n",
    "state_modality = ModalityConfig(\n",
    "    delta_indices=[0],\n",
    "    modality_keys=[\"state.left_arm\", \"state.right_arm\", \"state.left_hand\", \"state.right_hand\"],\n",
    ")\n",
    "\n",
    "action_modality = ModalityConfig(\n",
    "    delta_indices=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "    modality_keys=[\"action.left_arm\", \"action.right_arm\", \"action.left_hand\", \"action.right_hand\"],\n",
    ")\n",
    "\n",
    "language_modality = ModalityConfig(\n",
    "    delta_indices=[0],\n",
    "    modality_keys=[\"annotation.human.task_description\"],\n",
    ")\n",
    "\n",
    "modality_configs = {\n",
    "    \"video\": video_modality,\n",
    "    \"state\": state_modality,\n",
    "    \"action\": action_modality,\n",
    "    \"language\": language_modality,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-18 15:48:31.873238: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-18 15:48:31.891980: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-09-18 15:48:31.891996: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-09-18 15:48:31.892548: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-09-18 15:48:31.896395: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-18 15:48:32.450867: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "`use_fast` is set to `True` but the image processor class does not have a fast version.  Falling back to the slow version.\n"
     ]
    }
   ],
   "source": [
    "from gr00t.data.transform.base import ComposedModalityTransform\n",
    "from gr00t.data.transform import VideoToTensor, VideoCrop, VideoResize, VideoColorJitter, VideoToNumpy\n",
    "from gr00t.data.transform.state_action import StateActionToTensor, StateActionTransform\n",
    "from gr00t.data.transform.concat import ConcatTransform\n",
    "from gr00t.model.transforms import GR00TTransform\n",
    "\n",
    "\n",
    "# select the transforms you want to apply to the data\n",
    "to_apply_transforms = ComposedModalityTransform(\n",
    "    transforms=[\n",
    "        # video transforms\n",
    "        VideoToTensor(apply_to=video_modality.modality_keys, backend=\"torchvision\"),\n",
    "        VideoCrop(apply_to=video_modality.modality_keys, scale=0.95, backend=\"torchvision\"),\n",
    "        VideoResize(apply_to=video_modality.modality_keys, height=224, width=224, interpolation=\"linear\", backend=\"torchvision\" ),\n",
    "        VideoColorJitter(apply_to=video_modality.modality_keys, brightness=0.3, contrast=0.4, saturation=0.5, hue=0.08, backend=\"torchvision\"),\n",
    "        VideoToNumpy(apply_to=video_modality.modality_keys),\n",
    "\n",
    "        # state transforms\n",
    "        StateActionToTensor(apply_to=state_modality.modality_keys),\n",
    "        StateActionTransform(apply_to=state_modality.modality_keys, normalization_modes={\n",
    "            \"state.left_arm\": \"min_max\",\n",
    "            \"state.right_arm\": \"min_max\",\n",
    "            \"state.left_hand\": \"min_max\",\n",
    "            \"state.right_hand\": \"min_max\",\n",
    "        }),\n",
    "\n",
    "        # action transforms\n",
    "        StateActionToTensor(apply_to=action_modality.modality_keys),\n",
    "        StateActionTransform(apply_to=action_modality.modality_keys, normalization_modes={\n",
    "            \"action.right_arm\": \"min_max\",\n",
    "            \"action.left_arm\": \"min_max\",\n",
    "            \"action.right_hand\": \"min_max\",\n",
    "            \"action.left_hand\": \"min_max\",\n",
    "        }),\n",
    "\n",
    "        # ConcatTransform\n",
    "        ConcatTransform(\n",
    "            video_concat_order=video_modality.modality_keys,\n",
    "            state_concat_order=state_modality.modality_keys,\n",
    "            action_concat_order=action_modality.modality_keys,\n",
    "        ),\n",
    "        # model-specific transform\n",
    "        GR00TTransform(\n",
    "            state_horizon=len(state_modality.delta_indices),\n",
    "            action_horizon=len(action_modality.delta_indices),\n",
    "            max_state_dim=64,\n",
    "            max_action_dim=32,\n",
    "        ),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.2 Load the dataset\n",
    "\n",
    "First we will visualize the dataset and then load it using the `LeRobotSingleDataset` class. (without transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized dataset 57faa2cf516e008f96d91fe3b67ad53a74f012e6 with EmbodimentTag.NEW_EMBODIMENT\n"
     ]
    }
   ],
   "source": [
    "from gr00t.data.dataset import LeRobotSingleDataset\n",
    "\n",
    "train_dataset = LeRobotSingleDataset(\n",
    "    dataset_path=dataset_path,\n",
    "    modality_configs=modality_configs,\n",
    "    embodiment_tag=embodiment_tag,\n",
    "    video_backend=\"torchvision_av\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['video.cam_right_high', 'state.left_arm', 'state.right_arm', 'state.left_hand', 'state.right_hand', 'action.left_arm', 'action.right_arm', 'action.left_hand', 'action.right_hand', 'annotation.human.task_description'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use matplotlib to visualize the images\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(train_dataset[0].keys())\n",
    "\n",
    "images = []\n",
    "for i in range(5):\n",
    "    image = train_dataset[i][\"video.cam_right_high\"][0]\n",
    "    # image is in HWC format, convert it to CHW format\n",
    "    image = image.transpose(2, 0, 1)\n",
    "    images.append(image)   \n",
    "\n",
    "fig, axs = plt.subplots(1, 5, figsize=(20, 5))\n",
    "for i, image in enumerate(images):\n",
    "    axs[i].imshow(np.transpose(image, (1, 2, 0)))\n",
    "    axs[i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will initiate a dataset with our modality configs and transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized dataset 57faa2cf516e008f96d91fe3b67ad53a74f012e6 with EmbodimentTag.NEW_EMBODIMENT\n"
     ]
    }
   ],
   "source": [
    "train_dataset = LeRobotSingleDataset(\n",
    "    dataset_path=dataset_path,\n",
    "    modality_configs=modality_configs,\n",
    "    embodiment_tag=embodiment_tag,\n",
    "    video_backend=\"torchvision_av\",\n",
    "    transforms=to_apply_transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra Notes**:\n",
    " - We use a cached dataloader to accelerate training speed. The cached dataloader loads all data into memory, which significantly improves training performance. However, if your dataset is large or you're experiencing out-of-memory (OOM) errors, you can switch to the standard lerobot dataloader (`gr00t.data.dataset.LeRobotSingleDataset`). It uses the same API as the cached dataloader, so you can switch back and forth without any changes to your code.\n",
    " - we use torchvision_av as the video backend, the video encoding is in av instead of standard h264\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load the model\n",
    "\n",
    "The training process is done in 3 steps:\n",
    "- 2.1: Load the base model from HuggingFace or a local path\n",
    "- 2.2: Prepare training args\n",
    "- 2.3: Run the training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.1 Load the base model\n",
    "\n",
    "We'll use the `from_pretrained_for_tuning` method to load the model. This method allows us to specify which parts of the model to tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained dual brain from nvidia/GR00T-N1.5-3B\n",
      "Tune backbone vision tower: False\n",
      "Tune backbone LLM: False\n",
      "Tune action head projector: True\n",
      "Tune action head DiT: True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "389924cfd6214a1faba80a6628a372c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tune backbone llm: False\n",
      "Tune backbone visual: True\n",
      "Total number of DiT parameters:  550386688\n",
      "Total number of SelfAttentionTransformer parameters:  201433088\n",
      "Tune action head projector: True\n",
      "Tune action head diffusion model: True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c64d5cc27241408cbebb61363be8d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tune backbone llm: False\n",
      "Tune backbone visual: False\n",
      "Warning: No backbone trainable parameters found.\n",
      "Tune action head projector: True\n",
      "Tune action head diffusion model: True\n",
      "trainable params: 26,214,400 || all params: 2,750,377,920 || trainable%: 0.9531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): GR00T_N1_5(\n",
       "      (backbone): EagleBackbone(\n",
       "        (eagle_model): Eagle2_5_VLForConditionalGeneration(\n",
       "          (vision_model): SiglipVisionModel(\n",
       "            (vision_model): SiglipVisionTransformer(\n",
       "              (embeddings): SiglipVisionEmbeddings(\n",
       "                (patch_embedding): Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14), padding=valid)\n",
       "                (position_embedding): Embedding(256, 1152)\n",
       "              )\n",
       "              (encoder): SiglipEncoder(\n",
       "                (layers): ModuleList(\n",
       "                  (0-26): 27 x SiglipEncoderLayer(\n",
       "                    (layer_norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "                    (self_attn): SiglipAttention(\n",
       "                      (k_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "                      (v_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "                      (q_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "                      (out_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "                    )\n",
       "                    (layer_norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "                    (mlp): SiglipMLP(\n",
       "                      (activation_fn): PytorchGELUTanh()\n",
       "                      (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "                      (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (post_layernorm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "              (head): SiglipMultiheadAttentionPoolingHead(\n",
       "                (attention): MultiheadAttention(\n",
       "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=1152, out_features=1152, bias=True)\n",
       "                )\n",
       "                (layernorm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "                (mlp): SiglipMLP(\n",
       "                  (activation_fn): PytorchGELUTanh()\n",
       "                  (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "                  (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (language_model): Qwen3ForCausalLM(\n",
       "            (model): Qwen3Model(\n",
       "              (embed_tokens): Embedding(151680, 2048)\n",
       "              (layers): ModuleList(\n",
       "                (0-11): 12 x Qwen3DecoderLayer(\n",
       "                  (self_attn): Qwen3Attention(\n",
       "                    (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "                    (k_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "                    (v_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "                    (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "                    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "                    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "                  )\n",
       "                  (mlp): Qwen3MLP(\n",
       "                    (gate_proj): Linear(in_features=2048, out_features=6144, bias=False)\n",
       "                    (up_proj): Linear(in_features=2048, out_features=6144, bias=False)\n",
       "                    (down_proj): Linear(in_features=6144, out_features=2048, bias=False)\n",
       "                    (act_fn): SiLU()\n",
       "                  )\n",
       "                  (input_layernorm): Qwen3RMSNorm((2048,), eps=1e-06)\n",
       "                  (post_attention_layernorm): Qwen3RMSNorm((2048,), eps=1e-06)\n",
       "                )\n",
       "              )\n",
       "              (norm): Qwen3RMSNorm((2048,), eps=1e-06)\n",
       "              (rotary_emb): Qwen3RotaryEmbedding()\n",
       "            )\n",
       "            (lm_head): Linear(in_features=2048, out_features=151680, bias=False)\n",
       "          )\n",
       "          (mlp1): Sequential(\n",
       "            (0): Linear(in_features=1152, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (eagle_linear): Identity()\n",
       "      )\n",
       "      (action_head): FlowmatchingActionHead(\n",
       "        (model): DiT(\n",
       "          (timestep_encoder): TimestepEncoder(\n",
       "            (time_proj): Timesteps()\n",
       "            (timestep_embedder): TimestepEmbedding(\n",
       "              (linear_1): Linear(in_features=256, out_features=1536, bias=True)\n",
       "              (act): SiLU()\n",
       "              (linear_2): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): AdaLayerNorm(\n",
       "                (silu): SiLU()\n",
       "                (linear): Linear(in_features=1536, out_features=3072, bias=True)\n",
       "                (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              )\n",
       "              (attn1): Attention(\n",
       "                (to_q): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_k): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2048, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2048, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_v): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2048, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2048, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GELU(\n",
       "                    (proj): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                  (2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "                  (3): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (final_dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "            (1): BasicTransformerBlock(\n",
       "              (norm1): AdaLayerNorm(\n",
       "                (silu): SiLU()\n",
       "                (linear): Linear(in_features=1536, out_features=3072, bias=True)\n",
       "                (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              )\n",
       "              (attn1): Attention(\n",
       "                (to_q): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_k): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_v): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GELU(\n",
       "                    (proj): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                  (2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "                  (3): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (final_dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "            (2): BasicTransformerBlock(\n",
       "              (norm1): AdaLayerNorm(\n",
       "                (silu): SiLU()\n",
       "                (linear): Linear(in_features=1536, out_features=3072, bias=True)\n",
       "                (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              )\n",
       "              (attn1): Attention(\n",
       "                (to_q): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_k): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2048, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2048, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_v): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2048, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2048, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GELU(\n",
       "                    (proj): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                  (2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "                  (3): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (final_dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "            (3): BasicTransformerBlock(\n",
       "              (norm1): AdaLayerNorm(\n",
       "                (silu): SiLU()\n",
       "                (linear): Linear(in_features=1536, out_features=3072, bias=True)\n",
       "                (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              )\n",
       "              (attn1): Attention(\n",
       "                (to_q): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_k): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_v): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GELU(\n",
       "                    (proj): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                  (2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "                  (3): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (final_dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "            (4): BasicTransformerBlock(\n",
       "              (norm1): AdaLayerNorm(\n",
       "                (silu): SiLU()\n",
       "                (linear): Linear(in_features=1536, out_features=3072, bias=True)\n",
       "                (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              )\n",
       "              (attn1): Attention(\n",
       "                (to_q): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_k): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2048, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2048, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_v): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2048, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2048, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GELU(\n",
       "                    (proj): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                  (2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "                  (3): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (final_dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "            (5): BasicTransformerBlock(\n",
       "              (norm1): AdaLayerNorm(\n",
       "                (silu): SiLU()\n",
       "                (linear): Linear(in_features=1536, out_features=3072, bias=True)\n",
       "                (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              )\n",
       "              (attn1): Attention(\n",
       "                (to_q): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_k): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_v): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GELU(\n",
       "                    (proj): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                  (2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "                  (3): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (final_dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "            (6): BasicTransformerBlock(\n",
       "              (norm1): AdaLayerNorm(\n",
       "                (silu): SiLU()\n",
       "                (linear): Linear(in_features=1536, out_features=3072, bias=True)\n",
       "                (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              )\n",
       "              (attn1): Attention(\n",
       "                (to_q): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_k): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2048, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2048, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_v): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2048, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2048, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GELU(\n",
       "                    (proj): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                  (2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "                  (3): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (final_dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "            (7): BasicTransformerBlock(\n",
       "              (norm1): AdaLayerNorm(\n",
       "                (silu): SiLU()\n",
       "                (linear): Linear(in_features=1536, out_features=3072, bias=True)\n",
       "                (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              )\n",
       "              (attn1): Attention(\n",
       "                (to_q): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_k): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_v): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GELU(\n",
       "                    (proj): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                  (2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "                  (3): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (final_dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "            (8): BasicTransformerBlock(\n",
       "              (norm1): AdaLayerNorm(\n",
       "                (silu): SiLU()\n",
       "                (linear): Linear(in_features=1536, out_features=3072, bias=True)\n",
       "                (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              )\n",
       "              (attn1): Attention(\n",
       "                (to_q): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_k): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2048, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2048, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_v): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2048, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2048, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GELU(\n",
       "                    (proj): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                  (2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "                  (3): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (final_dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "            (9): BasicTransformerBlock(\n",
       "              (norm1): AdaLayerNorm(\n",
       "                (silu): SiLU()\n",
       "                (linear): Linear(in_features=1536, out_features=3072, bias=True)\n",
       "                (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              )\n",
       "              (attn1): Attention(\n",
       "                (to_q): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_k): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_v): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GELU(\n",
       "                    (proj): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                  (2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "                  (3): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (final_dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "            (10): BasicTransformerBlock(\n",
       "              (norm1): AdaLayerNorm(\n",
       "                (silu): SiLU()\n",
       "                (linear): Linear(in_features=1536, out_features=3072, bias=True)\n",
       "                (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              )\n",
       "              (attn1): Attention(\n",
       "                (to_q): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_k): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2048, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2048, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_v): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2048, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2048, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GELU(\n",
       "                    (proj): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                  (2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "                  (3): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (final_dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "            (11): BasicTransformerBlock(\n",
       "              (norm1): AdaLayerNorm(\n",
       "                (silu): SiLU()\n",
       "                (linear): Linear(in_features=1536, out_features=3072, bias=True)\n",
       "                (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              )\n",
       "              (attn1): Attention(\n",
       "                (to_q): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_k): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_v): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GELU(\n",
       "                    (proj): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                  (2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "                  (3): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (final_dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "            (12): BasicTransformerBlock(\n",
       "              (norm1): AdaLayerNorm(\n",
       "                (silu): SiLU()\n",
       "                (linear): Linear(in_features=1536, out_features=3072, bias=True)\n",
       "                (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              )\n",
       "              (attn1): Attention(\n",
       "                (to_q): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_k): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2048, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2048, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_v): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2048, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2048, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GELU(\n",
       "                    (proj): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                  (2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "                  (3): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (final_dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "            (13): BasicTransformerBlock(\n",
       "              (norm1): AdaLayerNorm(\n",
       "                (silu): SiLU()\n",
       "                (linear): Linear(in_features=1536, out_features=3072, bias=True)\n",
       "                (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              )\n",
       "              (attn1): Attention(\n",
       "                (to_q): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_k): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_v): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GELU(\n",
       "                    (proj): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                  (2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "                  (3): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (final_dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "            (14): BasicTransformerBlock(\n",
       "              (norm1): AdaLayerNorm(\n",
       "                (silu): SiLU()\n",
       "                (linear): Linear(in_features=1536, out_features=3072, bias=True)\n",
       "                (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              )\n",
       "              (attn1): Attention(\n",
       "                (to_q): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_k): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2048, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2048, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_v): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2048, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2048, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GELU(\n",
       "                    (proj): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                  (2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "                  (3): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (final_dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "            (15): BasicTransformerBlock(\n",
       "              (norm1): AdaLayerNorm(\n",
       "                (silu): SiLU()\n",
       "                (linear): Linear(in_features=1536, out_features=3072, bias=True)\n",
       "                (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              )\n",
       "              (attn1): Attention(\n",
       "                (to_q): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_k): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_v): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1536, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=1536, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=False)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GELU(\n",
       "                    (proj): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                  (2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "                  (3): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (final_dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_out): LayerNorm((1536,), eps=1e-06, elementwise_affine=False)\n",
       "          (proj_out_1): Linear(in_features=1536, out_features=3072, bias=True)\n",
       "          (proj_out_2): Linear(in_features=1536, out_features=1024, bias=True)\n",
       "        )\n",
       "        (state_encoder): CategorySpecificMLP(\n",
       "          (layer1): CategorySpecificLinear()\n",
       "          (layer2): CategorySpecificLinear()\n",
       "        )\n",
       "        (action_encoder): MultiEmbodimentActionEncoder(\n",
       "          (W1): CategorySpecificLinear()\n",
       "          (W2): CategorySpecificLinear()\n",
       "          (W3): CategorySpecificLinear()\n",
       "          (pos_encoding): SinusoidalPositionalEncoding()\n",
       "        )\n",
       "        (action_decoder): CategorySpecificMLP(\n",
       "          (layer1): CategorySpecificLinear()\n",
       "          (layer2): CategorySpecificLinear()\n",
       "        )\n",
       "        (future_tokens): Embedding(32, 1536)\n",
       "        (vlln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (vl_self_attention): SelfAttentionTransformer(\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0-3): 4 x BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2048, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=2048, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_k): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2048, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=2048, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_v): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2048, out_features=128, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=128, out_features=2048, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GELU(\n",
       "                    (proj): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.2, inplace=False)\n",
       "                  (2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "                  (3): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (final_dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (position_embedding): Embedding(1024, 1536)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gr00t.model.gr00t_n1 import GR00T_N1_5\n",
    "from gr00t.utils.peft import get_lora_model\n",
    "\n",
    "BASE_MODEL_PATH = \"nvidia/GR00T-N1.5-3B\"\n",
    "TUNE_LLM = False            # Whether to tune the LLM\n",
    "TUNE_VISUAL = False          # Whether to tune the visual encoder\n",
    "TUNE_PROJECTOR = True       # Whether to tune the projector\n",
    "TUNE_DIFFUSION_MODEL = True # Whether to tune the diffusion model\n",
    "\n",
    "model = GR00T_N1_5.from_pretrained(\n",
    "    pretrained_model_name_or_path=BASE_MODEL_PATH,\n",
    "    tune_llm=TUNE_LLM,  # backbone's LLM\n",
    "    tune_visual=TUNE_VISUAL,  # backbone's vision tower\n",
    "    tune_projector=TUNE_PROJECTOR,  # action head's projector\n",
    "    tune_diffusion_model=TUNE_DIFFUSION_MODEL,  # action head's DiT\n",
    ")\n",
    "\n",
    "# Set the model's compute_dtype to bfloat16\n",
    "model.compute_dtype = \"bfloat16\"\n",
    "model.config.compute_dtype = \"bfloat16\"\n",
    "\n",
    "model = get_lora_model(\n",
    "    model,\n",
    "    rank=128,\n",
    "    lora_alpha=128,\n",
    "    lora_dropout=0.1,\n",
    "    action_head_only=True,\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.2 Prepare training args\n",
    "\n",
    "We use huggingface `TrainingArguments` to configure the training process. Here are the main parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "output_dir = \"output/model/path\"    # CHANGE THIS ACCORDING TO YOUR LOCAL PATH\n",
    "per_device_train_batch_size = 8     # CHANGE THIS ACCORDING TO YOUR GPU MEMORY\n",
    "max_steps = 2000                      # CHANGE THIS ACCORDING TO YOUR NEEDS\n",
    "report_to = \"wandb\"\n",
    "dataloader_num_workers = 8\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    run_name=None,\n",
    "    remove_unused_columns=False,\n",
    "    deepspeed=\"\",\n",
    "    gradient_checkpointing=False,\n",
    "    bf16=True,\n",
    "    tf32=True,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=1,\n",
    "    dataloader_num_workers=dataloader_num_workers,\n",
    "    dataloader_pin_memory=False,\n",
    "    dataloader_persistent_workers=True,\n",
    "    optim=\"adamw_torch\",\n",
    "    adam_beta1=0.95,\n",
    "    adam_beta2=0.999,\n",
    "    adam_epsilon=1e-8,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=1e-5,\n",
    "    warmup_ratio=0.05,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    logging_steps=10.0,\n",
    "    num_train_epochs=300,\n",
    "    max_steps=max_steps,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    save_total_limit=8,\n",
    "    report_to=report_to,\n",
    "    seed=42,\n",
    "    do_eval=False,\n",
    "    ddp_find_unused_parameters=False,\n",
    "    ddp_bucket_cap_mb=100,\n",
    "    torch_compile_mode=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.3 Initialize the training runner and run the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: output/model/path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataloader length: 35112\n",
      "train dataset length: 280895\n",
      "GPU memory before training: 7.174342155456543 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard logs will be saved to: output/model/path/runs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbrainstoorm\u001b[0m (\u001b[33mbrainstoorm-personal\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to render HTML, can't import display from ipython.core\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to render HTML, can't import display from ipython.core\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to render HTML, can't import display from ipython.core\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to render HTML, can't import display from ipython.core\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to render HTML, can't import display from ipython.core\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2000/2000 03:51, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.791700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.325900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.479500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.249100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.948900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.745800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.562900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.412700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.344200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.313300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.320700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.305900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.210300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.231000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.226800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.196000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.207600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.198200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.200500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.185800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.172500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.203000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.187600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.208600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.163300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.152800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.181200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.176600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.179800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.170100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.160400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.150300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.143000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.129500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.148800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.148200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.133700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.138100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.148400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.120800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.139900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.113400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.130700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.124800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.132000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.166100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.129300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.128000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.134500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.123400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.098700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.129200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.121000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.124200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.114200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.112200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.126300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.132500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.118300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.105300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.113300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.104000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.136100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.096500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.125800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.102600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.112700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.104000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.127900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.094200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.092900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.114300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.105800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.104300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.144100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.100100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.095100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.100600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.107300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.132500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.116300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.118400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.105700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.120300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.092300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.094500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.111400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>0.105100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.085900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.099900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.159800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.083000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.092800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>0.114600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.084500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>0.082400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.095300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>0.096200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.097400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>0.091700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.096400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.101200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.101500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>0.116100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.110200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>0.097900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.104800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>0.115800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.078100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>0.100700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.126300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.106300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.095700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>0.084400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.088100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>0.107000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.101200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>0.109300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>0.091700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>0.097700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>0.096600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.086600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.105300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>0.084400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.088900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>0.101500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.101600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1310</td>\n",
       "      <td>0.093200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.092300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1330</td>\n",
       "      <td>0.074100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>0.090900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>0.093100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1370</td>\n",
       "      <td>0.077000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.080500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1390</td>\n",
       "      <td>0.084200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.082100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1410</td>\n",
       "      <td>0.098600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>0.107100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1430</td>\n",
       "      <td>0.079700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.085700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.105100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>0.095400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1470</td>\n",
       "      <td>0.091300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>0.080900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1490</td>\n",
       "      <td>0.106700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.100200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1510</td>\n",
       "      <td>0.086500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1520</td>\n",
       "      <td>0.108300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1530</td>\n",
       "      <td>0.101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1540</td>\n",
       "      <td>0.083000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.085300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.098100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1570</td>\n",
       "      <td>0.094400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1580</td>\n",
       "      <td>0.076200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1590</td>\n",
       "      <td>0.094200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.081900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1610</td>\n",
       "      <td>0.080500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.084800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1630</td>\n",
       "      <td>0.133200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1640</td>\n",
       "      <td>0.085500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.085100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1660</td>\n",
       "      <td>0.083400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1670</td>\n",
       "      <td>0.079900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.077600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1690</td>\n",
       "      <td>0.091700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.087300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1710</td>\n",
       "      <td>0.124200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1720</td>\n",
       "      <td>0.081800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1730</td>\n",
       "      <td>0.090400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.083700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.083100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1760</td>\n",
       "      <td>0.087200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1770</td>\n",
       "      <td>0.078700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1780</td>\n",
       "      <td>0.110300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1790</td>\n",
       "      <td>0.080700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.089400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1810</td>\n",
       "      <td>0.085000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1820</td>\n",
       "      <td>0.086100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1830</td>\n",
       "      <td>0.103700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1840</td>\n",
       "      <td>0.094400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.103000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.101100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1870</td>\n",
       "      <td>0.092000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1880</td>\n",
       "      <td>0.071600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1890</td>\n",
       "      <td>0.085100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.083800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1910</td>\n",
       "      <td>0.092900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.090300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1930</td>\n",
       "      <td>0.077800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1940</td>\n",
       "      <td>0.080400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.076200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1960</td>\n",
       "      <td>0.112100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1970</td>\n",
       "      <td>0.076900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.102900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1990</td>\n",
       "      <td>0.071100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.078900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gr00t.experiment.runner import TrainRunner\n",
    "\n",
    "experiment = TrainRunner(\n",
    "    train_dataset=train_dataset,\n",
    "    model=model,\n",
    "    training_args=training_args,\n",
    ")\n",
    "\n",
    "experiment.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the 1k offline validation results vs 10k offline validation results:\n",
    "\n",
    "**Finetuning Results on Unitree G1 Block Stacking Dataset:**\n",
    "\n",
    "| 1k Steps | 10k Steps |\n",
    "| --- | --- |\n",
    "| ![1k](../media/g1_ft_1k.png) | ![10k](../media/g1_ft_10k.png) |\n",
    "| MSE: 0.0181 | MSE: 0.0022 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gr00t.utils.eval import calc_mse_for_single_trajectory\n",
    "import warnings\n",
    "\n",
    "\n",
    "mse = calc_mse_for_single_trajectory(\n",
    "    finetuned_policy,\n",
    "    dataset,\n",
    "    traj_id=0,\n",
    "    modality_keys=[\"right_arm\", \"right_hand\"],   # we will only evaluate the right arm and right hand\n",
    "    steps=150,\n",
    "    action_horizon=16,\n",
    "    plot=True\n",
    ")\n",
    "\n",
    "print(\"MSE loss for trajectory 0:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
